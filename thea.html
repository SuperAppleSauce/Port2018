<!DOCTYPE html>
<html>

<head>

  <title>Alexis_Trevizo</title>
  <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width">

  <link rel="stylesheet" href="path/to/font-awesome/css/font-awesome.min.css">

  <link rel="stylesheet" type="text/css" href="stylesProject.css">

</head>
<header>


  <div id="brand">
  <a href="./index.html"> 
      <h2>alexisTrevizo</h2>
  </a>    
  </div>
 <nav id="nav">
  <a href="#"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M1 12L12 21V16H21.5V7.5H12V1.76025L1 12Z" fill="#E3AB05" stroke="#222D3D" stroke-width="2" stroke-linejoin="round"/>
</svg>
<br>projects</a>
      
  <a href="#"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M11 9C13.2091 9 15 7.20914 15 5C15 2.79086 13.2091 1 11 1C8.79086 1 7 2.79086 7 5C7 7.20914 8.79086 9 11 9Z" fill="#E3AB05"/>
<path d="M1 22C1 14.8408 5.47715 12 11 12C16.5228 12 21 14.8408 21 22H1Z" fill="#E3AB05"/>
<path d="M11 9C13.2091 9 15 7.20914 15 5C15 2.79086 13.2091 1 11 1C8.79086 1 7 2.79086 7 5C7 7.20914 8.79086 9 11 9Z" stroke="#2C3749" stroke-width="2" stroke-linejoin="round"/>
<path d="M1 22C1 14.8408 5.47715 12 11 12C16.5228 12 21 14.8408 21 22H1Z" stroke="#2C3749" stroke-width="2" stroke-linejoin="round"/>
</svg>


<br>about</a>
      
  <a href="#"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M7 1C3.68629 1 1 3.6863 1 7V10.8621C1 14.1758 3.68629 16.8621 7 16.8621H17.5303L23 20.4138L21.6574 15.6188C23.082 14.5218 24 12.7992 24 10.8621V7C24 3.68629 21.3137 1 18 1H7Z" fill="#E3AB05"/>
<svg width="25" height="25" viewBox="0 0 25 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M7 1C3.68629 1 1 3.6863 1 7V10.8621C1 14.1758 3.68629 16.8621 7 16.8621H17.5303L23 20.4138L21.6574 15.6188C23.082 14.5218 24 12.7992 24 10.8621V7C24 3.68629 21.3137 1 18 1H7Z" fill="#E3AB05" stroke="#1A222D" stroke-width="2"/>
</svg>
<br>contact</a>
      
</nav>
</header>
 <img class="imageM"   src="http://gdurl.com/IeRw"
      alt= "a young man places a Haptic feedback pad on his shoulder" width = "100%"> 


<head>
  <div class="sidenavP">
    <p class="eyeBrow">PROJECT NAME</p>
    <p class="projectName">Thea</p>
    <p class="eyeBrow">DATE</p>
    <p>June 2018</p>
    <p class="eyeBrow">MATERIALS</p>
      <p>Accessibility, Human Centered Design, Voice UI, Physical Computing, 5G</p>
    <p class="eyeBrow">CONTRIBUTORS</p>
    <p>Alexis Trevizo, Darshan Alatar Patel, Lauren Fox, Alina Peng and Chanel Luu Hai</p>

  </div>
  </head>

<body>
  <div class="containerP"> 

 <img class="imageD"   src="http://gdurl.com/IeRw"
      alt= "a young man places a Haptic feedback pad on his shoulder" width = "100%"> 

    
      
  
      <p class="eyeBrow">Details</p>
      <p>Thea enables those who are visually impaired to confidently move through their world.</p>

      <br>
       <p>Every year, Moment (which is now part of Verizon) conducts a summer research project which focuses on the intersection of an emerging technology, social impact, and the human-centered design process.
       </p>
       <br>
          <p>At the beginning of the summer, we were tasked to design a near-future product or service that improves the experience for people with mobility challenges in NYC, by leveraging granular location data, 5G technology and AI available to Verizon today and in the near future.
        </p>
        <br>
        <p>
         Our team narrowed down the prompt and through secondary research, we have decided to focus on mobility challenges faced by those who are blind or visually impaired when navigating New York City, or similar urban environments.</p>
         <br>
          <p>When it comes to navigation, solutions for sighted people are more prevalent than they are for the blind and low vision community. The blind and low vision community is often underserved.</p>

          <p class="eyeBrow">Research</p>
          <p>We conducted research throughout NYC, interviewing and more importantly, co-designing with BLV individuals. Through interviews with 43+ BLV users and 20+ subject matter experts, including people from Verizon’s 5G innovation Lab, Verizon’s accessibility group, and disability volunteer coordinators</p>
          <br>
           <p> From our research, we found four major problem areas:</p>
            <img src="http://gdurl.com/d2E6" width = "100%">
        <p class="eyeBrow">Pre-Planning</p>
       <p>A majority of visually impaired persons are too anxious to navigate outside of their homes and their comfort zones, and when they do, they have to plan every step down to the wire, to minimize their risk as much as possible. </P>
        
        <img src="http://gdurl.com/LJiF" width = "100%">

        <p class="eyeBrow">Path details</p>
        <p>We found that the the visually-impaired community wants more specific details about their the surrounding environment. Instead of the  the simple navigation directions that apps like Google maps provide.</p>

          <img src="http://gdurl.com/aDzR" width = "100%">

          <p class="eyeBrow">Sensory Overload</p>

          <p> A unique problem to the blind and low vision community. The blind and low vision community rely heavily on sound as their main source of information output; hence, wearing headphones can be distracting, because in doing so, they lose touch with their environment and audio cues. </p>

          <img src="http://gdurl.com/i7BE" width = "100%">

          <p class="eyeBrow">Last Foot Navigation</p>

          <p>The last mile often poses many navigational challenges for BLV users, especially in indoor spaces and if they’re trying to find a moving target (for ex, reach a friend).


      
      <p class="eyeBrow">Design</p>
      <p>We chose to create an affordable and customizable wearable that would work in parallel with a voice assistance named Thea. Thea is an on the go navigation assistant that is able to plan trips, and provide highly detailed directions. Thea communicates via voice input/output and haptic feedback.   </p>
      
      <p class="eyeBrow">Process Images</p>
        <img class="ppictures" src="http://gdurl.com/4pQc" width = "100%">
      <img class="ppictures" src="http://gdurl.com/7PcE" width = "100%">
      <img class="ppictures" src="http://gdurl.com/NsYW" width = "100%">
      <img class="ppictures" src="http://gdurl.com/oKAV" width = "100%">
      <img class="ppictures" src="http://gdurl.com/vXuA" width = "100%">
      <br>
       <br>

      <a href="https://medium.com/design-intelligence/thea/home
"><p>Read more about Thea and our design process! </p></a>




  </div>
</body>

<script src="https://use.fontawesome.com/89e8d09064.js"></script>
<!-- jquery -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
<script src="http://code.jquery.com/ui/1.9.2/jquery-ui.js"></script>

<!-- my JavaScript -->
<!--         var mixer = mixitup('.container', {
    controls: {
        toggleDefault: 'none'
    }
});
 -->
<!-- mixItup -->
<script src="js/mixitup.min.js"></script>
<script>
  function openNav() {
    document.getElementById("mySidenav").style.height = "100%";
  }

  function closeNav() {
    document.getElementById("mySidenav").style.height = "0%";
  }
  var containerEl = document.querySelector('.container');
  var mixer = mixitup(containerEl);
</script>

</html>
